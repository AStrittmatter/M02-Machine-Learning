{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65af0075-cc5e-4be9-8b9e-0202da5f6742",
   "metadata": {},
   "source": [
    "# Automating Dataset Handling in R\n",
    "\n",
    "In this tutorial, we explore a practical and efficient approach to getting started with a data science project in R: automating the download, unzipping, and loading of datasets. This process not only saves time but also introduces you to the concept of functions in Râ€”a fundamental skill for any aspiring data scientist.\n",
    "\n",
    "### Why Create a Custom Function?\n",
    "\n",
    "- **Time-saving:** Automating repetitive tasks like downloading, unzipping, and loading datasets saves a significant amount of time.\n",
    "- **Skill Enhancement:** Building a custom function for these tasks is not only practical for any data science project but also an excellent way to understand the power and flexibility of functions in R.\n",
    "\n",
    "### Tutorial Overview\n",
    "\n",
    "This tutorial walks you through creating a custom function to automate the process of handling the Student Performance dataset from the UCI Machine Learning Repository. Here's what we'll cover:\n",
    "\n",
    "1. **Creating a Function in R to Download and Unzip the Dataset:** We'll define a custom function that automates the download and extraction of datasets, specifically focusing on the Student Performance dataset.\n",
    "2. **Automating Dataset Handling with a Custom Split Function:** Building on our data preparation, we'll create a function to efficiently split the dataset into training and testing sets for machine learning purposes.\n",
    "3. **Enhancing R Data Science Skills by Generating Synthetic Data:** To further our exploration, we'll introduce a method for generating synthetic data for regression analysis, simulating real-world data scenarios and testing our models.\n",
    "\n",
    "Through this process, you'll gain a deeper understanding of how functions in R can be used to streamline and enhance your data science skills with R, from initial data handling to preparing data for machine learning and creating synthetic datasets for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49388ed1-a304-4cb1-b593-b8bb3b1097e1",
   "metadata": {},
   "source": [
    "## Creating a Function in R\r\n",
    "\r\n",
    "To create a function in R, you use the `function()` keyword. The basic syntax of a function is as follows:\r\n",
    "\r\n",
    "```R\r\n",
    "my_function <- function(arg1, arg2, ...) {\r\n",
    "  # Function body\r\n",
    "  # Code to execute\r\n",
    "  # Return a\n",
    "```\n",
    "\n",
    "\n",
    "Let's create a very simple function that adds two numbers together. This function will take two arguments (the numbers to be added) and will return their sum. value\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b94e8911-1abb-484c-9d6a-1a01ab7c7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_numbers <- function(number1, number2) {\n",
    "  sum <- number1 + number2\n",
    "  return(sum)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee857f-3bc7-4e5f-8faa-39ce0887f3fa",
   "metadata": {},
   "source": [
    "Once you've defined a function in R, it's ready to be used. However, to make it work, you must supply it with the necessary inputs, known as **arguments** or **parameters**. These inputs are the data or values that the function needs to perform its task.\n",
    "\n",
    "For our simple `add_numbers` function, we defined it to take two parameters: `number1` and `number2`. These parameters are placeholders for the numbers we want to add together.\r\n",
    "\r\n",
    "To use the `add_numbers` function, follow these steps:\r\n",
    "\r\n",
    "1. **Call the Function:** Start by writing the name of the function you want to use, in this case, `add_numbers`.\r\n",
    "\r\n",
    "2. **Provide Arguments:** Next, provide the values (arguments) for `number1` and `number2` inside parentheses, separated by a comma. For example, to add 5 and 3, you would write `add_numbers(5, 3)`.\r\n",
    "\r\n",
    "3. **Capture the Result:** The function returns a value, which you can assign to a variable or use directly. To save the result of adding 5 and 3 into a variable called `result`, you would write `result <- add_numbers(5, 3)`.\r\n",
    "\r\n",
    "4. **Display the Result:** Finally, you can view the result by printing the variable `result` using the `print()` function, like so: `print(result)`.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc564487-6002-4fd1-899f-ad477e41a940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 8\n"
     ]
    }
   ],
   "source": [
    "result <- add_numbers(5, 3)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241e830-083f-4b66-aa5a-c4b006c7dcaf",
   "metadata": {},
   "source": [
    "## Function 1: Download and Unzip the Dataset\n",
    "\n",
    "The `download_and_unzip` function in R is designed to automate the process of downloading and extracting the contents of a zip file from a given URL. This function is particularly useful in data science workflows where acquiring and preparing data is a preliminary step. Below is a detailed breakdown of what each part of the function does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0207b027-02c6-4a69-9578-4a09d54ae425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "download_and_unzip <- function(download_url, dest_dir, zip_file_name) {\n",
    "  # Ensure the destination directory exists\n",
    "  if (!dir.exists(dest_dir)) {\n",
    "    dir.create(dest_dir)\n",
    "  }\n",
    "  \n",
    "  # Define the zip file path\n",
    "  zip_file_path <- file.path(dest_dir, zip_file_name)\n",
    "  \n",
    "  # Download the zip file\n",
    "  download.file(url = download_url, destfile = zip_file_path, method = \"auto\")\n",
    "  \n",
    "  # Unzip the file\n",
    "  unzip(zipfile = zip_file_path, exdir = dest_dir)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e1f59-a6b4-4a11-9367-583c8c115817",
   "metadata": {},
   "source": [
    "download_url: The URL from which the zip file will be downloaded.\r\n",
    "dest_dir: The destination directory where the zip file will be stored and unzipped.\r\n",
    "zip_file_name: The name of the zip file as it will be saved on the local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8328a-9399-4093-ad69-e8411f6ce60e",
   "metadata": {},
   "source": [
    "## Function 2: How to Split Datasets for Machine Learning in R\n",
    "\n",
    "The `split_data` function is designed to divide a dataset into training and testing subsets, which is a crucial step in preparing data for machine learning models. It takes two arguments: the path to a dataset file and a split ratio, the latter of which determines the proportion of the dataset to be used for training. By default, the split ratio is set to 0.8, meaning that 80% of the data will be allocated for training purposes, while the remaining 20% will be set aside for testing the model.\r\n",
    "\r\n",
    "The function works as follows: First, it reads the datasns. Next, to ensure the train-test split is reproducible in future runs, it sets a random seed. It then calculates the number of rows that should belong to the training set based on the split ratio and randomly selects that many rows from the dataset. These selected rows form the training set, while the rest of the rows are used for the testing set.\r\n",
    "\r\n",
    "Finally, the function returns both subsets in a structured list, making it straightforward to access the training and testing data separately for model training and evaluation. This methodical approach to splitting data ensures that models are not tested on the same data they were trained on, a practice that helps in assessing the model's performance on unseen data accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20157e3-b42c-41e7-8d0c-6ed99d5ef5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data <- function(data, split_ratio = 0.8) {\n",
    "  # Splitting the data into train and test sets\n",
    "  set.seed(123) # For reproducibility\n",
    "  training_sample <- sample(nrow(data), size = floor(nrow(data) * split_ratio))\n",
    "  train_set <- data[training_sample, ]\n",
    "  test_set <- data[-training_sample, ]\n",
    "  \n",
    "  # Return a list containing the train and test datasets\n",
    "  return(list(train_set = train_set, test_set = test_set))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f953b105-3f91-4d11-a345-df226fc4c2e9",
   "metadata": {},
   "source": [
    "## Streamlining Dataset Preparation: Download, Unzip, and Split Workflow in R\r\n",
    "\r\n",
    "Thied code snippet demonstrates a streamlined sequence of operations for preparing a dataset for machine learning analysis in R. The process is tailored for the \"Student Performance\" dataset from the UCI Machine Learning Repository, and it encompasses the following steps:\r\n",
    "\r\n",
    "1. **Specifying Dataset Details**: The process begins by defining essential details such as the dataset's download URL, the destination directory for storing the data, the name of the zip file, and the specific CSV file name within the zip archive. These details are crucial for automating the subsequent steps.\r\n",
    "\r\n",
    "2. **Automating Download and Unzipping**: With the `download_and_unzip` function, the dataset is fetched from its source URL and extracted into the designated directory. This function eradicates the need for manual intervention in the data preparation phase.\r\n",
    "\r\n",
    "3. **Setting Up the Dataset Path**: Utilizing the `file.path` function, the path to the actual data file (CSV) is established. This is done by concatenating the destination directory and the data file name, forming a complete path to the dataset.\r\n",
    "\r\n",
    "4. **Reading the Dataset**: Once the dataset is in place, it is loaded into R using the `read.csv` function. The dataset is read from the constructed path, with parameters adjusted as necessary (e.g., separator character).\r\n",
    "\r\n",
    "5. **Preparing for Data Splitting**: At this point, the data is ready to be passed to the `split_data` function, marking the transition to the next stage of the workflowâ€”splitting the dataset into training and testing sets. This division is pivotal for machine learning model training, allowing for an assessment of the model's performance on unseen data.\r\n",
    "\r\n",
    "By encapsulating these steps in a concise and reproducible R script, the workflow facilitates a seamless progression from acquiring raw data to generating ready-to-use training and testing sets, laying the groundwork required in most machine learning projects.\r\n",
    " R script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849101d5-3a7f-4b02-ab83-4b7e043277c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given dataset details\n",
    "download_url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\"\n",
    "dest_dir <- \"student-performance\"\n",
    "zip_file_name <- \"student-performance.zip\"\n",
    "data_file <- \"student-mat.csv\"\n",
    "\n",
    "# Download and unzip the dataset\n",
    "download_and_unzip(download_url, dest_dir, zip_file_name)\n",
    "\n",
    "# Define the path to the dataset CSV file\n",
    "data_file_path <- file.path(dest_dir, data_file)\n",
    "\n",
    "# Read the dataset\n",
    "data <- read.csv(data_file_path, sep = \";\")\n",
    "\n",
    "# Now data is ready to be passed to the split_data function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8e7771-2c89-4a65-baf9-221a2231116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and test sets\n",
    "datasets <- split_data(data)\n",
    "train_set <- datasets$train_set\n",
    "test_set <- datasets$test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb0c92-9933-491f-bab3-eae4080ec1c1",
   "metadata": {},
   "source": [
    "### Importance of Data Preparation in Machine Learning algorithms \n",
    "\n",
    "When working with any machine learning method, the correct preparation of data is crucial for the success of your model. This involves ensuring that all input features (predictors) and the target variable are in a format that the algorithm can process effectively. Lasso regression is a type of linear model that adds a penalty on the size of coefficients to reduce overfitting and perform variable selection. For effective application, the input data must meet specific criteria:\n",
    "\n",
    "#### Numeric Data\n",
    "Lasso regression, like many other machine learning algorithms, requires that all input data be numeric. This necessity arises because the mathematical operations underlying these models, such as matrix multiplication, are defined for numbers, not for text or categorical data.\n",
    "\n",
    "#### One-hot Encoding for Categorical Variables\n",
    "Since Lasso can only process numeric input, categorical variables (like 'sex' or 'school') that contain text or class labels need to be converted into a numeric format. One common approach is one-hot encoding, which creates new binary (0 or 1) columns for each category of the original variable. Each record in the dataset is then marked with a 1 in the column corresponding to its category, ensuring that the model can interpret and use these variables.\n",
    "\n",
    "#### Data Cleaning\n",
    "Beyond converting categorical variables, data cleaning is essential for addressing other common issues like missing values (NAs). While some level of data cleaning might be required for any model, specific preprocessing steps like one-hot encoding are particularly relevant for Lasso regression due to its sensitivity to the input feature set and its ability to select variables.\n",
    "\n",
    "The `preprocess_data` function you're applying performs these crucial steps. It automatically detects categorical columns, applies one-hot encoding, and ensures the target variable is numeric, preparing the dataset for Lasso regression. This preprocessing is not just a mere formality; it's a foundational step that aligns the data with the assumptions and requirements of the Lasso method. Without this preprocessing, the Lasso model cannot be fitted properly, leading to errors or suboptimal performance.\n",
    "\n",
    "Understanding this as a \"black box,\" you should recognize that proper data preparation:\n",
    "\n",
    "- Transforms the data into a format compatible with the algorithm.\n",
    "- Is a standard and necessary step in the machine learning workflow.\n",
    "- Enhances model performance by enabling the algorithm to accurately interpret and learn from the data.\n",
    "\n",
    "By emphasizing the role of data preprocessing, you can appreciate its importance in the broader context of building reliable, effective machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554d417-84fc-4f68-8af1-e9c9842832c5",
   "metadata": {},
   "source": [
    "## Function 3: Generating Synthetic Data for Regression Analysis\n",
    "\n",
    "In this part of our tutorial, we're generating synthetic data to simulate a regression analysis scenario. Here's a breakdown of each step:\n",
    "\n",
    "1. **Setting Seed for Reproducibility**: We start by setting the seed to 42 using `set.seed(42)`. This ensures that the random numbers generated in subsequent steps will be the same each time the tutorial is run, providing reproducibility.\n",
    "\n",
    "2. **Defining Number of Observations and Features**: We specify the number of observations `n` as 1000 and the number of features `p` as 20. These parameters determine the size and complexity of our synthetic dataset.\n",
    "\n",
    "3. **Generating Predictor Variables**: We create a matrix `X` of random normal values with dimensions `n` rows by `p` columns. These values represent the predictor variables or features in our dataset.\n",
    "\n",
    "4. **Generating Coefficients**: We generate a vector `beta` of random normal values with length `p`. These coefficients will be used to generate the response variable.\n",
    "\n",
    "5. **Generating Response Variable**: We compute the response variable `y` using a linear combination of the predictor variables and coefficients, along with some random noise. This simulates the relationship between the predictors and the outcome in a regression model.\n",
    "\n",
    "6. **Combining Data**: We combine the predictor variables `X` and the response variable `y` into a single dataframe `data`. This dataframe represents our complete synthetic dataset for analysis.\n",
    "\n",
    "\n",
    "\n",
    "Overall, this tutorial segment allows us to create synthetic data that can be used for regression analysis, experimentation, and testing of statistical models.\n",
    "\n",
    "we will streamline our code by using a custom function called `generate_synthetic_data`. This function simplifies the process of generating synthetic data for regression analysis. It accepts three parameters:\n",
    "\n",
    "- `n`: The number of observations in the dataset (default is 1000).\n",
    "- `p`: The number of features (predictor variables) in the dataset (default is 20).\n",
    "- `seed`: The random seed for reproducibility (default is 42).\n",
    "\n",
    "By utilizing this function, we can easily create synthetic datasets tailored to our specific needs, making it convenient for experimentation and model testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e3feeec-b6b2-4947-8c24-f235b93a1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 Ã— 21</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X1</th><th scope=col>X2</th><th scope=col>X3</th><th scope=col>X4</th><th scope=col>X5</th><th scope=col>X6</th><th scope=col>X7</th><th scope=col>X8</th><th scope=col>X9</th><th scope=col>X10</th><th scope=col>â‹¯</th><th scope=col>X12</th><th scope=col>X13</th><th scope=col>X14</th><th scope=col>X15</th><th scope=col>X16</th><th scope=col>X17</th><th scope=col>X18</th><th scope=col>X19</th><th scope=col>X20</th><th scope=col>y</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>â‹¯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 1.3709584</td><td> 2.3250585</td><td> 0.2505781</td><td>-0.6856617</td><td>-0.1418087</td><td> 0.07122244</td><td> 0.1728323</td><td> 1.41634143</td><td>-0.05745257</td><td>-0.92213502</td><td>â‹¯</td><td>-0.29447605</td><td> 0.05379511</td><td>-1.800429915</td><td>-2.296071583</td><td>-1.0202102</td><td> 0.4956498</td><td> 0.1100047</td><td> 1.02512529</td><td> 1.7904948</td><td> 4.5613831</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>-0.5646982</td><td> 0.5241222</td><td>-0.2779240</td><td>-0.7927145</td><td>-0.8138981</td><td> 0.97029003</td><td>-1.2729637</td><td> 0.55723399</td><td>-0.24903540</td><td>-0.49581727</td><td>â‹¯</td><td> 0.46405252</td><td> 0.75343075</td><td>-0.106430450</td><td> 0.004654244</td><td>-0.7541671</td><td> 0.5185875</td><td>-0.7405873</td><td>-1.44915517</td><td>-0.2623922</td><td>-0.6723308</td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 0.3631284</td><td> 0.9707334</td><td>-1.7247357</td><td>-0.4070042</td><td>-0.3255406</td><td> 0.31003525</td><td>-0.8678954</td><td> 0.98124131</td><td>-1.52416211</td><td>-3.11046226</td><td>â‹¯</td><td>-1.53705786</td><td> 0.24985048</td><td> 1.833467782</td><td>-1.616340892</td><td>-1.2256679</td><td>-0.4222029</td><td>-0.5106550</td><td> 1.41747467</td><td>-1.2974161</td><td> 1.0445109</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 0.6328626</td><td> 0.3769734</td><td>-2.0067049</td><td>-1.1486706</td><td> 0.3781574</td><td>-0.13954856</td><td> 0.6263211</td><td>-0.58618286</td><td> 0.46359103</td><td>-0.69276059</td><td>â‹¯</td><td> 0.98615417</td><td>-0.44410484</td><td> 1.023900729</td><td> 1.733129280</td><td>-1.0169050</td><td> 0.8631128</td><td>-0.9123660</td><td>-1.03530032</td><td> 0.6183881</td><td>-2.0303506</td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 0.4042683</td><td>-0.9959334</td><td>-1.2918083</td><td> 1.1157605</td><td>-1.9944854</td><td>-0.32631113</td><td>-0.1056306</td><td> 0.93917058</td><td>-1.18762073</td><td> 0.29890118</td><td>â‹¯</td><td> 0.63022215</td><td>-0.05027016</td><td>-0.004285927</td><td>-0.673676861</td><td> 1.7219955</td><td>-0.7779222</td><td>-1.2929680</td><td> 0.08533232</td><td>-0.2918216</td><td> 3.2898519</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-0.1061245</td><td>-0.5974829</td><td> 0.3658382</td><td>-0.8794568</td><td>-0.9993567</td><td>-0.11880951</td><td>-0.2563214</td><td>-0.06470105</td><td> 0.49406421</td><td>-0.06867297</td><td>â‹¯</td><td> 0.05734381</td><td>-0.46777918</td><td> 2.279912939</td><td>-0.094417675</td><td> 2.9998888</td><td> 0.1479133</td><td> 0.9051113</td><td> 0.24506831</td><td>-0.3011110</td><td> 7.2376467</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 Ã— 21\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & X1 & X2 & X3 & X4 & X5 & X6 & X7 & X8 & X9 & X10 & â‹¯ & X12 & X13 & X14 & X15 & X16 & X17 & X18 & X19 & X20 & y\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & â‹¯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 &  1.3709584 &  2.3250585 &  0.2505781 & -0.6856617 & -0.1418087 &  0.07122244 &  0.1728323 &  1.41634143 & -0.05745257 & -0.92213502 & â‹¯ & -0.29447605 &  0.05379511 & -1.800429915 & -2.296071583 & -1.0202102 &  0.4956498 &  0.1100047 &  1.02512529 &  1.7904948 &  4.5613831\\\\\n",
       "\t2 & -0.5646982 &  0.5241222 & -0.2779240 & -0.7927145 & -0.8138981 &  0.97029003 & -1.2729637 &  0.55723399 & -0.24903540 & -0.49581727 & â‹¯ &  0.46405252 &  0.75343075 & -0.106430450 &  0.004654244 & -0.7541671 &  0.5185875 & -0.7405873 & -1.44915517 & -0.2623922 & -0.6723308\\\\\n",
       "\t3 &  0.3631284 &  0.9707334 & -1.7247357 & -0.4070042 & -0.3255406 &  0.31003525 & -0.8678954 &  0.98124131 & -1.52416211 & -3.11046226 & â‹¯ & -1.53705786 &  0.24985048 &  1.833467782 & -1.616340892 & -1.2256679 & -0.4222029 & -0.5106550 &  1.41747467 & -1.2974161 &  1.0445109\\\\\n",
       "\t4 &  0.6328626 &  0.3769734 & -2.0067049 & -1.1486706 &  0.3781574 & -0.13954856 &  0.6263211 & -0.58618286 &  0.46359103 & -0.69276059 & â‹¯ &  0.98615417 & -0.44410484 &  1.023900729 &  1.733129280 & -1.0169050 &  0.8631128 & -0.9123660 & -1.03530032 &  0.6183881 & -2.0303506\\\\\n",
       "\t5 &  0.4042683 & -0.9959334 & -1.2918083 &  1.1157605 & -1.9944854 & -0.32631113 & -0.1056306 &  0.93917058 & -1.18762073 &  0.29890118 & â‹¯ &  0.63022215 & -0.05027016 & -0.004285927 & -0.673676861 &  1.7219955 & -0.7779222 & -1.2929680 &  0.08533232 & -0.2918216 &  3.2898519\\\\\n",
       "\t6 & -0.1061245 & -0.5974829 &  0.3658382 & -0.8794568 & -0.9993567 & -0.11880951 & -0.2563214 & -0.06470105 &  0.49406421 & -0.06867297 & â‹¯ &  0.05734381 & -0.46777918 &  2.279912939 & -0.094417675 &  2.9998888 &  0.1479133 &  0.9051113 &  0.24506831 & -0.3011110 &  7.2376467\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 Ã— 21\n",
       "\n",
       "| <!--/--> | X1 &lt;dbl&gt; | X2 &lt;dbl&gt; | X3 &lt;dbl&gt; | X4 &lt;dbl&gt; | X5 &lt;dbl&gt; | X6 &lt;dbl&gt; | X7 &lt;dbl&gt; | X8 &lt;dbl&gt; | X9 &lt;dbl&gt; | X10 &lt;dbl&gt; | â‹¯ â‹¯ | X12 &lt;dbl&gt; | X13 &lt;dbl&gt; | X14 &lt;dbl&gt; | X15 &lt;dbl&gt; | X16 &lt;dbl&gt; | X17 &lt;dbl&gt; | X18 &lt;dbl&gt; | X19 &lt;dbl&gt; | X20 &lt;dbl&gt; | y &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 |  1.3709584 |  2.3250585 |  0.2505781 | -0.6856617 | -0.1418087 |  0.07122244 |  0.1728323 |  1.41634143 | -0.05745257 | -0.92213502 | â‹¯ | -0.29447605 |  0.05379511 | -1.800429915 | -2.296071583 | -1.0202102 |  0.4956498 |  0.1100047 |  1.02512529 |  1.7904948 |  4.5613831 |\n",
       "| 2 | -0.5646982 |  0.5241222 | -0.2779240 | -0.7927145 | -0.8138981 |  0.97029003 | -1.2729637 |  0.55723399 | -0.24903540 | -0.49581727 | â‹¯ |  0.46405252 |  0.75343075 | -0.106430450 |  0.004654244 | -0.7541671 |  0.5185875 | -0.7405873 | -1.44915517 | -0.2623922 | -0.6723308 |\n",
       "| 3 |  0.3631284 |  0.9707334 | -1.7247357 | -0.4070042 | -0.3255406 |  0.31003525 | -0.8678954 |  0.98124131 | -1.52416211 | -3.11046226 | â‹¯ | -1.53705786 |  0.24985048 |  1.833467782 | -1.616340892 | -1.2256679 | -0.4222029 | -0.5106550 |  1.41747467 | -1.2974161 |  1.0445109 |\n",
       "| 4 |  0.6328626 |  0.3769734 | -2.0067049 | -1.1486706 |  0.3781574 | -0.13954856 |  0.6263211 | -0.58618286 |  0.46359103 | -0.69276059 | â‹¯ |  0.98615417 | -0.44410484 |  1.023900729 |  1.733129280 | -1.0169050 |  0.8631128 | -0.9123660 | -1.03530032 |  0.6183881 | -2.0303506 |\n",
       "| 5 |  0.4042683 | -0.9959334 | -1.2918083 |  1.1157605 | -1.9944854 | -0.32631113 | -0.1056306 |  0.93917058 | -1.18762073 |  0.29890118 | â‹¯ |  0.63022215 | -0.05027016 | -0.004285927 | -0.673676861 |  1.7219955 | -0.7779222 | -1.2929680 |  0.08533232 | -0.2918216 |  3.2898519 |\n",
       "| 6 | -0.1061245 | -0.5974829 |  0.3658382 | -0.8794568 | -0.9993567 | -0.11880951 | -0.2563214 | -0.06470105 |  0.49406421 | -0.06867297 | â‹¯ |  0.05734381 | -0.46777918 |  2.279912939 | -0.094417675 |  2.9998888 |  0.1479133 |  0.9051113 |  0.24506831 | -0.3011110 |  7.2376467 |\n",
       "\n"
      ],
      "text/plain": [
       "  X1         X2         X3         X4         X5         X6          X7        \n",
       "1  1.3709584  2.3250585  0.2505781 -0.6856617 -0.1418087  0.07122244  0.1728323\n",
       "2 -0.5646982  0.5241222 -0.2779240 -0.7927145 -0.8138981  0.97029003 -1.2729637\n",
       "3  0.3631284  0.9707334 -1.7247357 -0.4070042 -0.3255406  0.31003525 -0.8678954\n",
       "4  0.6328626  0.3769734 -2.0067049 -1.1486706  0.3781574 -0.13954856  0.6263211\n",
       "5  0.4042683 -0.9959334 -1.2918083  1.1157605 -1.9944854 -0.32631113 -0.1056306\n",
       "6 -0.1061245 -0.5974829  0.3658382 -0.8794568 -0.9993567 -0.11880951 -0.2563214\n",
       "  X8          X9          X10         â‹¯ X12         X13         X14         \n",
       "1  1.41634143 -0.05745257 -0.92213502 â‹¯ -0.29447605  0.05379511 -1.800429915\n",
       "2  0.55723399 -0.24903540 -0.49581727 â‹¯  0.46405252  0.75343075 -0.106430450\n",
       "3  0.98124131 -1.52416211 -3.11046226 â‹¯ -1.53705786  0.24985048  1.833467782\n",
       "4 -0.58618286  0.46359103 -0.69276059 â‹¯  0.98615417 -0.44410484  1.023900729\n",
       "5  0.93917058 -1.18762073  0.29890118 â‹¯  0.63022215 -0.05027016 -0.004285927\n",
       "6 -0.06470105  0.49406421 -0.06867297 â‹¯  0.05734381 -0.46777918  2.279912939\n",
       "  X15          X16        X17        X18        X19         X20       \n",
       "1 -2.296071583 -1.0202102  0.4956498  0.1100047  1.02512529  1.7904948\n",
       "2  0.004654244 -0.7541671  0.5185875 -0.7405873 -1.44915517 -0.2623922\n",
       "3 -1.616340892 -1.2256679 -0.4222029 -0.5106550  1.41747467 -1.2974161\n",
       "4  1.733129280 -1.0169050  0.8631128 -0.9123660 -1.03530032  0.6183881\n",
       "5 -0.673676861  1.7219955 -0.7779222 -1.2929680  0.08533232 -0.2918216\n",
       "6 -0.094417675  2.9998888  0.1479133  0.9051113  0.24506831 -0.3011110\n",
       "  y         \n",
       "1  4.5613831\n",
       "2 -0.6723308\n",
       "3  1.0445109\n",
       "4 -2.0303506\n",
       "5  3.2898519\n",
       "6  7.2376467"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_synthetic_data <- function(n = 1000, p = 20, seed = 42) {\n",
    "  # Set seed for reproducibility\n",
    "  set.seed(seed)\n",
    "  \n",
    "  # Generate predictor variables\n",
    "  X <- matrix(rnorm(n * p), nrow = n)\n",
    "  \n",
    "  # Generate coefficients\n",
    "  beta <- rnorm(p)\n",
    "  \n",
    "  # Generate response variable\n",
    "  y <- X %*% beta + rnorm(n)\n",
    "  \n",
    "  # Combine predictor variables and response variable into a dataframe\n",
    "  data <- data.frame(X, y)\n",
    "  \n",
    "  return(data)\n",
    "}\n",
    "\n",
    "# Generate synthetic data with default parameters\n",
    "synthetic_data <- generate_synthetic_data()\n",
    "\n",
    "# Print the first few rows of the dataset\n",
    "head(synthetic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538d6b4-8ab0-4f70-af1e-e56a24cef7a0",
   "metadata": {},
   "source": [
    "Now that we have our synthetic dataset ready, it's time to prepare it for our analysis. We'll use the `split_data` function that we're already familiar with. This function will help us split our data into training and testing sets, allowing us to train our models on one portion of the data and validate their performance on another. Here's how we do it:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23acce0f-0493-49ba-a846-3b1f41d7f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use the split_data function to split the data into training and testing sets\n",
    "split_data <- split_data(synthetic_data, split_ratio = 0.8)\n",
    "# Extract the training and testing sets\n",
    "train_set <- split_data$train_set\n",
    "test_set <- split_data$test_set\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
