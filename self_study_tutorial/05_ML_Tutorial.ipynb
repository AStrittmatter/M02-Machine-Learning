{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96220bcf-faf0-4e0c-99c5-18d6ee745db5",
   "metadata": {},
   "source": [
    "# Predictive Analysis of Student Performance in Math Courses using R and glmnet\r\n",
    "\r\n",
    "In this Machine Learning (ML) tutorial, we'll explore the realm of predictive analytics with a focus on student performance in math courses. Our goal is to leverage predictive modeling to identify students who may require additional academic support, potentially guiding them towards private lessons to enhance their learning outcomes. Utilizing the `glmnet` library in R, we aim to demonstrate a comprehensive approach to predicting student grades based on various socio-economic and school-related factors.\r\n",
    "\r\n",
    "## Dataset Overview\r\n",
    "\r\n",
    "We base our analysthe student datasetRdata`, sourced from detailed records of student achievements in Portuguese schools. These datasets provide a rich tapestry of data encompassing students' math grades, socio-economic backgrounds, and school-related characteristics. Below is a brief overview of the types of data we'll be examining:\r\n",
    "\r\n",
    "- **Math Grade:** The primary focus of our analysis, representing students' final grades in math.\r\n",
    "- **Socio-economic Characteristics:** Attributes detailing students' family backgrounds, parents' occupations, home resources like internet access, and additional factors that could influence academic performance.\r\n",
    "- **School Related Features:** Information covering school attendance, study habits, previous academic failures, absences, and other relevant variables.\r\n",
    "\r\n",
    "For an in-depth look at all the variables included in our datasets, please consult the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Student+Performance) for a comprehensive data description.\r\n",
    "\r\n",
    "## Tutorial Outline\r\n",
    "\r\n",
    "This tutorial is structured to guide participants through the entire process of a machine learning project, from initial data handling to the final stages of model evaluation and prediction. Here’s what you can expect:\r\n",
    "\r\n",
    "### Data Preparation\r\n",
    "Using the `r_functions.r` script, we'll streamline the  loading, cleaning, and preparing our data for analysis. These functions are essential for ensuring our data is in the right format for modeling.\r\n",
    "\r\n",
    "### Model Training\r\n",
    "With the `glmnet` package, we'll fit a generalized linear model to our training data. This phase involves feature selection and model parameter tuning to optimize our predictive model's performance.\r\n",
    "\r\n",
    "### Evaluation and Prediction\r\n",
    "We'll assess our model's accuracy using the test dataset, evaluating its effectiveness in predicting math grades. This step will enable us to identify students who could benefit from additional educational support.\r\n",
    "\r\n",
    "This tutorial offers more than just a walkthrough of machine learning implementation; it provides a deeper understanding of the data and strategic insights necessary for impactful predictive modeling in the educational domain. Whether you're an experienced data scientist or a newcomer to the field, this tutorial promises to enrich your knowledge and skills in educational data analytics.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67945bd1-b923-49a0-9541-bf39ef2bea2e",
   "metadata": {},
   "source": [
    "## Loading Training and Testing Datasets in R\n",
    "\n",
    "In this code snippet, we're loading the training and testing datasets necessary for our analysis. These datasets are stored as `.Rdata` files, a format used in R for saving and loading objects. By using the `load()` function, we directly read these files into our R environment. The datasets are located in the `scripts_and_data` directory, within the broader `self_study_tutorial` directory of the course's materials. The paths provided are absolute, ensuring that R can locate and load the datasets regardless of the current working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d2b986-0ef6-4408-92ba-514212b95546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train = load(\"/home/jupyter-mlcourseuser/M02-Machine-Learning/self_study_tutorial/scripts_and_data/student-mat-train.Rdata\")\n",
    "\n",
    "# Load the test dataset\n",
    "test = load(\"/home/jupyter-mlcourseuser/M02-Machine-Learning/self_study_tutorial/scripts_and_data/student-mat-test.Rdata\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702affb1-8d1a-4325-9c3c-9b362ea83e52",
   "metadata": {},
   "source": [
    "This action makes all the valuable functions we developed in the past tutorial instantly available for use. Among these, we have functions for data downloading, preprocessing, and splitting, which are foundational for any machine learning project.\n",
    "\n",
    "For instance, consider the scenario where we aim to predict student performance in a math course. A critical first step involves obtaining and preparing the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07306d3c-df32-43e6-a80b-d3b826cf1111",
   "metadata": {},
   "source": [
    "# Estimating Linear Regression to Predict Student Performance\r\n",
    "\r\n",
    "In this section of our tutorial, we focus on estimating a linear regression model to predict students' final math grades (G3) based on a variety of socio-economic and school-related features. Linear regression is a basic yet powerful statistical method that elucidates the relationship between one dependent variable and one or more independent variables.\r\n",
    "\r\n",
    "The core idea is to fit a linear equation to observed data, which, in our case, involves using the `lm()` function in R. The `lm()` function, which stands for linear model, requires a formula specifying the model to be fitted and the dataset for the model fitting.\r\n",
    "\r\n",
    "After fitting our model, we'll proceed to assess its performance. We do this by predicting math grades on our test dataset and then calculating the Mean Squared Error (MSE) of these predictions. MSE is a critical measure that quantifies the average of the squares of errors; essentially, it's the average squared difference between the observed actual outcomes and the predictions made by the model. Generally, a lower MSE signifies a model with high accuracy in its predictions.\r\n",
    "\r\n",
    "Let's proceed with the code implementation:s a\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43c94b5-2da8-4423-a443-3dc358d2dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "Loaded glmnet 4.1-8\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = G3 ~ ., data = train)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.5524 -1.9313  0.1568  1.8190  8.5320 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 14.62145    3.68541   3.967 0.000103 ***\n",
       "sex         -0.62733    0.49221  -1.275 0.204052    \n",
       "age         -0.16293    0.19173  -0.850 0.396517    \n",
       "address     -0.42789    0.53423  -0.801 0.424171    \n",
       "famsize     -0.47520    0.46329  -1.026 0.306346    \n",
       "Pstatus      0.26090    0.63117   0.413 0.679816    \n",
       "Medu         0.34875    0.25380   1.374 0.171046    \n",
       "Fedu         0.09652    0.23729   0.407 0.684661    \n",
       "traveltime   0.22792    0.32065   0.711 0.478090    \n",
       "studytime    0.68759    0.27570   2.494 0.013496 *  \n",
       "failures    -0.69699    0.32437  -2.149 0.032934 *  \n",
       "schoolsup   -3.47010    0.67917  -5.109 7.91e-07 ***\n",
       "famsup      -0.76877    0.46120  -1.667 0.097202 .  \n",
       "paid        -0.39143    0.44383  -0.882 0.378945    \n",
       "activities   0.22703    0.42261   0.537 0.591760    \n",
       "nursery     -0.33598    0.54535  -0.616 0.538587    \n",
       "higher       0.15186    1.00918   0.150 0.880552    \n",
       "internet     0.71576    0.54760   1.307 0.192778    \n",
       "romantic    -0.24662    0.47302  -0.521 0.602715    \n",
       "famrel       0.14757    0.24275   0.608 0.543990    \n",
       "freetime     0.05355    0.21342   0.251 0.802169    \n",
       "goout       -0.12008    0.21991  -0.546 0.585672    \n",
       "Dalc        -0.14455    0.30271  -0.478 0.633554    \n",
       "Walc        -0.31261    0.22876  -1.367 0.173390    \n",
       "health      -0.09114    0.15123  -0.603 0.547454    \n",
       "absences    -0.06796    0.02550  -2.665 0.008373 ** \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 2.84 on 188 degrees of freedom\n",
       "Multiple R-squared:   0.33,\tAdjusted R-squared:  0.241 \n",
       "F-statistic: 3.705 on 25 and 188 DF,  p-value: 1.27e-07\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 9.300887\n"
     ]
    }
   ],
   "source": [
    "library(glmnet)\n",
    "library(dplyr)\n",
    "\n",
    "# Fit the linear regression model\n",
    "ols <- lm(G3 ~ ., data = train)\n",
    "# Display the summary of the model to understand its performance\n",
    "summary(ols)\n",
    "\n",
    "# Predicting the math grades for the test dataset\n",
    "test$predols <- predict(ols, newdata = test)\n",
    "\n",
    "# Calculating the Mean Squared Error (MSE) for our predictions\n",
    "predMSEols <- mean((test$G3 - test$predols)^2)\n",
    "# Print the MSE to the console\n",
    "print(predMSEols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cee87e-03d8-4adf-94fc-f9cbe7c4e8a1",
   "metadata": {},
   "source": [
    "##  Mean Squared Error (MSE) Overview\n",
    "\n",
    "The **Mean Squared Error (MSE)** is a critical metric in supervised learning, used to evaluate the performance of a predictive model. It calculates the average squared difference between the actual observed values and the model's predictions:\n",
    "\n",
    "$$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "where $n$ is the number of observations, $y_i$ the actual value, and $\\hat{y}_i$ the predicted value.\n",
    "\n",
    "### Objective\n",
    "\n",
    "- **Minimize MSE**: A lower MSE indicates a model that predicts more closely to the actual observations, showing higher accuracy.\n",
    "\n",
    "### Interpreting MSE: 9.300887\n",
    "\n",
    "- **Contextual Value**: MSE needs to be interpreted in relation to the scale of the target variable and compared to benchmarks or other models.\n",
    "- **Indication of Error**: An MSE of 9.300887 suggests that the model's predictions deviate from the actual values, with the squared average of these deviations being around 9.3. This value aids in understanding the model's accuracy.\n",
    "- **Improvement Marker**: Reductions in MSE across model iterations signal improvements in predictive accuracy, keeping in mind the balance with overfitting concerns.\n",
    "\n",
    "The goal is to develop a model that not only minimizes MSE but also generalizes well across different datasets.\n",
    "fferent datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006dde3-9b8f-4c23-818f-9d386bb8975a",
   "metadata": {},
   "source": [
    "## Predicting Student Performance with Lasso Regression\n",
    "\n",
    "The **Lasso** (Least Absolute Shrinkage and Selection Operator) minimizes the sum of squared residuals, with a penalty on the absolute size of the coefficients ($\\beta_j$). The objective function for Lasso is defined as:\n",
    "\n",
    "$$ \\min_{\\beta} \\left\\{ \\sum_{i=1}^{N} (Y_i - \\gamma - \\sum_{j=1}^{p} X_{ij} \\beta_j)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j| \\right\\}, $$\n",
    "\n",
    "where $p$ is the total number of control variables, and $\\lambda \\geq 0$ is the penalty term that regulates the degree of penalization. The Lasso performs both variable selection and regularization:\n",
    "\n",
    "- When $\\lambda = 0$, there's no penalization, making the Lasso equivalent to OLS.\n",
    "- As $\\lambda$ increases, some coefficients are shrunk towards zero, leading to exact zero coefficients for sufficiently large $\\lambda$.\n",
    "- The constant term ($\\gamma$) is not penalized.\n",
    "- Zero coefficients imply exclusion of corresponding variables from the model, making Lasso a model selection tool.\n",
    "\n",
    "## Tuning Parameter: $\\lambda$\n",
    "\n",
    "The penalty term $\\lambda$ is crucial for both Lasso and Ridge. Optimal $\\lambda$ can be determined through **cross-validation**:\n",
    "\n",
    "- Partition the sample into $k$ equally large folds.\n",
    "- Specify a grid of $\\lambda$ values.\n",
    "- For each $\\lambda$, estimate the model on $k-1$ folds, predict for the held-out fold, and measure the prediction error (e.g., MSE).\n",
    "- Repeat for all folds, averaging the prediction error.\n",
    "- Select $\\lambda$ with the best average prediction error or apply the one-standard-error rule.\n",
    "\n",
    "Before estimation, control variables are standardized, ensuring variable scaling does not impact the results.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a122fe0-f1d5-4c18-bdef-a27fae608668",
   "metadata": {},
   "source": [
    "### Estimating a Lasso Model and Determining Optimal Lambda with Cross-Validation\r\n",
    "\r\n",
    "In this part of our tutorial, we'll dive into how to estimate a Lasso regression model and use cross-validation to find the optimal lambda value, which balances model complexity and prediction accuracy. This process is crucial in preventing overfitting and underfitting, ensuring that our model generalizes well to new, unseen data.\r\n",
    "\r\n",
    "### Setting the Stage\r\n",
    "\r\n",
    "Before we begin, it's important to set a seed for replicability. This ensures that our results are consistent and can be reproduced by anyone rerunning this analy(27112019)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a0b4a67-4005-4582-86ae-30950fc6aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(27112019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2acc926-4d85-4033-b313-488cd1636953",
   "metadata": {},
   "source": [
    "## Estimating the Lasso Model\r\n",
    "\r\n",
    "The Lasso model is estimated using the `glmnet` package in R, which requires the predictor variables to be in a matrix format and the response variable to be numeric. Here, we're using the first 25 columns of our training dataset as predictors to estimate the model for predicting the `G3` variable, which represents student grades.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15079212-34f4-4702-bb67-8c0f58b2786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate a Lasso model using the first 25 columns as predictors\n",
    "lasso <- glmnet(as.matrix(train[,c(1:25)]), train$G3, alpha = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee501f-7b1d-4590-816c-f2445805c25c",
   "metadata": {},
   "source": [
    "## Cross-Validation to Determine Optimal Lambda\n",
    "\n",
    "Cross-validation is a technique used to assess how the results of a statistical analysis will generalize to an independent dataset. In the context of Lasso regression, we use cross-validation to determine the optimal lambda value. Lambda is a parameter that controls the amount of shrinkage: the larger the lambda, the more features are driven to zero. This process helps in feature selection and in preventing overfitting.\n",
    "\n",
    "The `cv.glmnet` function automatically performs cross-validation and is specified to use Mean Squared Error (MSE) as the measure to assess model accuracy. We've chosen a 5-fold cross-validation, meaning the data is split into 5 parts, with each part being used as a testing set at some point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722ca676-ae52-4d73-9018-1e252de30330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation to find the optimal lambda value\n",
    "lasso.cv <- cv.glmnet(as.matrix(train[,c(1:25)]), train$G3, type.measure = \"mse\", nfolds = 5, alpha = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3730ddea-a194-4314-aa90-abc732808516",
   "metadata": {},
   "source": [
    "## Results and Next Steps\n",
    "\n",
    "After running the cross-validation, the optimal lambda λ value is stored within `lasso.cv` and can be accessed using `lasso.cv$lambda.min` for the lambda that minimizes MSE, or `lasso.cv$lambda.1se` for the most regularized model within one standard error of the minimum.\n",
    "\n",
    "Understanding and selecting the optimal lambda allows us to balance model complexity and accuracy, tailoring our Lasso regression model to perform optimally on unseen data.\n",
    "\n",
    "In the next steps of our analysis, we would use this optimal lambda value to re-estimate our Lasso model or proceed with model evaluation, such as calculating MSE on a test set to gauge the model's prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14214010-6313-4f8e-9b04-db8d634f2fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Optimal lambda that minimizes cross-validated MSE: 0.156611125450941\"\n",
      "[1] \"Optimal lambda using one-standard-error-rule: 0.435779759613754\"\n"
     ]
    }
   ],
   "source": [
    "# Print the optimal lambda value\n",
    "print(paste0(\"Optimal lambda that minimizes cross-validated MSE: \", lasso.cv$lambda.min))\n",
    "print(paste0(\"Optimal lambda using one-standard-error-rule: \", lasso.cv$lambda.1se))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cd3e7e-eef0-421b-8db9-16f11ddb0b69",
   "metadata": {},
   "source": [
    "## Analyzing Lasso Coefficients and Calculating train Sample MSE\n",
    "\n",
    "In the code snippet below, we examine the coefficients of the Lasso model corresponding to the optimal lambda value determined through cross-validation. In Lasso regression, certain coefficients may take on a value of zero, indicating that the associated control variables are excluded from the model. This property of Lasso aids in simplifying the model by removing less relevant variables, thereby enhancing interpretability and generalization to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20672848-8f78-4996-af0c-448ae68295d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 x 1 sparse Matrix of class \"dgCMatrix\"\n",
      "                     s1\n",
      "(Intercept) 12.88293900\n",
      "sex         -0.34763178\n",
      "age         -0.04783289\n",
      "address      .         \n",
      "famsize     -0.11991735\n",
      "Pstatus      .         \n",
      "Medu         0.24728969\n",
      "Fedu         .         \n",
      "traveltime   .         \n",
      "studytime    0.32696194\n",
      "failures    -0.73390530\n",
      "schoolsup   -2.81748136\n",
      "famsup      -0.38144513\n",
      "paid        -0.11329474\n",
      "activities   0.02107000\n",
      "nursery      .         \n",
      "higher       .         \n",
      "internet     0.40280870\n",
      "romantic     .         \n",
      "famrel       0.02443835\n",
      "freetime     .         \n",
      "goout        .         \n",
      "Dalc        -0.02576019\n",
      "Walc        -0.32702432\n",
      "health       .         \n",
      "absences    -0.05943503\n"
     ]
    }
   ],
   "source": [
    "# Print Lasso coefficients\n",
    "print(coef(lasso.cv, s = \"lambda.min\"))\n",
    "\n",
    "# Save for later comparison\n",
    "coef_lasso1 <- coef(lasso.cv, s = \"lambda.min\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1e443-0268-426e-95f8-90edd0b7787f",
   "metadata": {},
   "source": [
    "###  Evaluating Model Performance with Test Sample Mean Squared Error (MSE)\n",
    "\n",
    "Following the coefficient analysis, we proceed to calculate the Mean Squared Error (MSE) in the test sample. The test sample MSE enables us to assess the performance of our Lasso model on unseen data and compare it with other estimators. By evaluating the model's accuracy on a separate test dataset, we ensure that our Lasso regression model can generalize effectively beyond the training data, providing reliable predictions in practical scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d8c10b-cd56-451a-9398-82677333f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE: 8.90119284460168\"\n"
     ]
    }
   ],
   "source": [
    "test$predlasso <- predict(lasso.cv, newx = as.matrix(test[,c(1:25)]), s = lasso.cv$lambda.min)\n",
    "\n",
    "# Calculate the MSE\n",
    "predMSElasso <- mean((test$G3 - test$predlasso)^2)\n",
    "print(paste0(\"MSE: \", predMSElasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3143397a-9e67-4fd8-9fb6-8388050aed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE: 8.90119284460168\"\n"
     ]
    }
   ],
   "source": [
    "# Fitted values\n",
    "test$predlasso <- predict(lasso.cv, newx = as.matrix(test[,c(1:25)]), s = lasso.cv$lambda.min)\n",
    "\n",
    "# Calculate the MSE\n",
    "predMSElasso <- mean((test$G3 - test$predlasso)^2)\n",
    "print(paste0(\"MSE: \", predMSElasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1001b-48a2-4055-99c2-abc4c42f23b0",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "The **Ridge** regression minimizes the sum of squared residuals, with a penalty on the squared size of the coefficients ($\\beta_j$). Its objective function is:\n",
    "\n",
    "$$ \\min_{\\beta} \\left\\{ \\sum_{i=1}^{N} (Y_i - \\gamma - \\sum_{j=1}^{p} X_{ij} \\beta_j)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2 \\right\\}. $$\n",
    "\n",
    "Similar to Lasso, larger $\\lambda$ values imply more penalization. However, unlike Lasso, Ridge does not set coefficients exactly to zero. Thus, Ridge is not used for variable selection but is more suitable when the true underlying model is dense.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de4d0ae-a3d3-45d0-aede-bd808e8731a9",
   "metadata": {},
   "source": [
    "## Ridge Regression Cross-Validation and Optimal Lambda Selection\n",
    "\n",
    "As you know, we will follow similar steps as we did for Lasso regression, but this time for Ridge regression. We'll begin by setting a starting value using `set.seed(27112019)` for reproducibility.\r\n",
    "\r\n",
    "Next, we'll conduct cross-validation for the Ridge regression model using the `cv.glmnet` function, aiming to determine the optimal lambda value. By specifying `type.measure = \"mse\"` and `nfolds = 5`, we ensure that the model's performance is evaluated based on Mean Squared Error (MSE) using a 5-fold cross-validation strategy.\r\n",
    "\r\n",
    "After completing the cross-validation process, we'll extract and output the optimal lambda value. This lambda value, accessible through `ridge.cv$lambda.min`, represents the parameter that minimizes the cross-validated MSE, indicating the optimal level of regularization for our Ridge regression model. Additionally, we'll obtain the lambda value based on the one-standard-error rule using `ridge.cv$lambda.1se`, providing an alternative perspective on selecting the regularization parameter.\r\n",
    "\r\n",
    "By performing Ridge regression cross-validation and obtaining the optimal lambda value, we'll ensure that our model is appropriately regularized, balancing bias and variance for optimal performance on unseen data.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c070447e-2168-4508-9863-bd6ebdd07a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set starting value\n",
    "set.seed(27112019)\n",
    "ridge <- glmnet(as.matrix(train[,c(1:25)]), train$G3, alpha = 0)\n",
    "# Cross-validate the Ridge model \n",
    "ridge.cv <- cv.glmnet(as.matrix(train[,c(1:25)]), train$G3, type.measure = \"mse\", nfolds = 5, alpha = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6ee96ed-d725-4001-bfd0-88d082456e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Optimal lambda that minimizes cross-validated MSE: 1.97620826614986\"\n",
      "[1] \"Optimal lambda using one-standard-error-rule: 10.5464291346655\"\n"
     ]
    }
   ],
   "source": [
    "# Print the optimal lambda value\n",
    "print(paste0(\"Optimal lambda that minimizes cross-validated MSE: \", ridge.cv$lambda.min))\n",
    "print(paste0(\"Optimal lambda using one-standard-error-rule: \", ridge.cv$lambda.1se))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72ea337f-abef-4fe0-ab91-5ffa55dbc124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 x 1 sparse Matrix of class \"dgCMatrix\"\n",
      "                     s1\n",
      "(Intercept) 12.94080662\n",
      "sex         -0.42225544\n",
      "age         -0.08314731\n",
      "address     -0.24984549\n",
      "famsize     -0.30876169\n",
      "Pstatus      0.11796154\n",
      "Medu         0.21089603\n",
      "Fedu         0.09683688\n",
      "traveltime   0.04969724\n",
      "studytime    0.36062997\n",
      "failures    -0.55560665\n",
      "schoolsup   -2.08642928\n",
      "famsup      -0.44044860\n",
      "paid        -0.24836700\n",
      "activities   0.20087023\n",
      "nursery     -0.11340779\n",
      "higher       0.38613173\n",
      "internet     0.50139834\n",
      "romantic    -0.15049638\n",
      "famrel       0.11637309\n",
      "freetime     0.02250704\n",
      "goout       -0.12642101\n",
      "Dalc        -0.17216585\n",
      "Walc        -0.19404329\n",
      "health      -0.05676600\n",
      "absences    -0.04516606\n"
     ]
    }
   ],
   "source": [
    "# Print Ridge coefficients\n",
    "print(coef(ridge.cv, s = \"lambda.min\"))\n",
    "\n",
    "# Save for later comparison\n",
    "coef_ridge <- coef(ridge.cv, s = \"lambda.min\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f84eb02-e168-4405-8d4b-d1d6dea8a199",
   "metadata": {},
   "source": [
    "In contrast to the Lasso model, the Ridge model keeps all control variables. Accordingly, Ridge is suited for dense models. In coparison to OLS, the Ridge coefficients are shrunken towards zero.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467c1fd-b6e6-46fb-8681-7c7115397d9c",
   "metadata": {},
   "source": [
    "Following the cross-validation and optimal lambda selection for Ridge regression, we proceed with predicting the test sample using the fitted model. We estimate the values using the predict function and calculate the Mean Squared Error (MSE) to evaluate the model's performance on the test data. This process allows us to assess how well the Ridge regression model generalizes to new, unseen data, providing insights into its predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f475f317-75a1-41cd-affb-5d71827cf7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE: 8.31374220052241\"\n"
     ]
    }
   ],
   "source": [
    "test$predridge <- predict(ridge, newx = as.matrix(test[,c(1:25)]), s = ridge.cv$lambda.min)\n",
    "\n",
    "# Calculate the MSE\n",
    "predMSEridge <- mean((test$G3 - test$predridge)^2)\n",
    "print(paste0(\"MSE: \", predMSEridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c10e0d-7d2e-49b6-aa25-8d343eabe195",
   "metadata": {},
   "source": [
    "# Comparing Regression Models: OLS, Lasso, and Ridge\n",
    "\n",
    "The output you've observed represents the mean squared error (MSE) values for three different regression models applied to your dataset: Ordinary Least Squares (OLS), Lasso, and Ridge regression. MSE is a common measure used to quantify the error of a model's predictions, where a lower MSE value indicates a model with better predictive accuracy. Below is an explanation of each model's MSE in your output:\n",
    "\n",
    "- **OLS Regression MSE (9.300887):** This MSE value is associated with the OLS regression model, the simplest form of linear regression that does not apply any regularization. The relatively higher MSE compared to the other models might suggest overfitting or a less effective capture of the underlying data structure.\n",
    "\n",
    "- **Lasso Regression MSE (8.901193):** Lasso regression, which incorporates an L1 penalty leading to coefficient sparsity (setting some coefficients to zero), shows a slightly improved MSE. This indicates better generalization, likely due to its feature selection effect, which helps in reducing overfitting.\n",
    "\n",
    "- **Ridge Regression MSE (8.313742):** The lowest MSE among the three models belongs to Ridge regression, which uses an L2 penalty to shrink the coefficients but not to zero. This suggests Ridge regression is the most accurate in predicting the data for this particular scenario. This improvement can be attributed to its capacity to handle multicollinearity more effectively than OLS, and potentially better than Lasso in this case.\n",
    "\n",
    "In essence, this comparison indicates that for the specific dataset and conditions at hand, Ridge regression outperforms both Lasso and OLS regression in terms of predictive accuracy. This underscores the benefit of incorporating regularization (both L1 and L2) to enhance model performance by mitigating overfitting and dealing more adeptly with multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c186d020-0316-46f6-b2dc-6a4790863d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 9.300887 8.901193 8.313742\n"
     ]
    }
   ],
   "source": [
    "print(c(predMSEols, predMSElasso, predMSEridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516bfac-b7a7-4cb9-b08f-3ff6ca3f2943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
