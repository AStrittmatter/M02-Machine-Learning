{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569fe9b5-2404-451a-8eb6-1933abc38e1f",
   "metadata": {},
   "source": [
    "# Automating Dataset Handling in R\n",
    "\n",
    "In this tutorial, we explore a practical and efficient approach to getting started with a data science project in R: automating the download, unzipping, and loading of datasets. This process not only saves time but also introduces you to the concept of functions in R—a fundamental skill for any aspiring data scientist.\n",
    "\n",
    "### Why Create a Custom Function?\n",
    "\n",
    "- **Time-saving:** Automating repetitive tasks like downloading, unzipping, and loading datasets saves a significant amount of time.\n",
    "- **Skill Enhancement:** Building a custom function for these tasks is not only practical for any data science project but also an excellent way to understand the power and flexibility of functions in R.\n",
    "\n",
    "### Tutorial Overview\n",
    "\n",
    "This tutorial walks you through creating a custom function to automate the process of handling the Student Performance dataset from the UCI Machine Learning Repository. Here's what we'll cover:\n",
    "\n",
    "1. **Creating a Function in R:** We'll start by defining a custom function tailored to automate the download, unzip, and load process.\n",
    "2. **Automating Dataset Handling:** We'll use the Student Performance dataset as a case study to demonstrate how the function works in practice.\n",
    "3. **Enhancing R Data Science Skills:** Through this process, you'll gain a deeper understanding of how functions in R can be used to streamline your data science skills with R.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd19ccf-6812-42b5-91c9-9b04b86b28e5",
   "metadata": {},
   "source": [
    "## Creating a Function in R\n",
    "\n",
    "To create a function in R, you use the `function()` keyword. The basic syntax of a function is as follows:\n",
    "\n",
    "```R\n",
    "my_function <- function(arg1, arg2, ...) {\n",
    "  # Function body\n",
    "  # Code to execute\n",
    "  # Return a\n",
    "```\n",
    "\n",
    "\n",
    "Let's create a very simple function that adds two numbers together. This function will take two arguments (the numbers to be added) and will return their sum. value\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50003885-0cf8-444e-ab30-8444fb7d46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_numbers <- function(number1, number2) {\n",
    "  sum <- number1 + number2\n",
    "  return(sum)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee6839-c97a-419a-9ff3-38c073609352",
   "metadata": {},
   "source": [
    "To use the `add_numbers` function, follow these steps:\n",
    "\n",
    "1. **Call the Function:** Start by writing the name of the function you want to use, in this case, `add_numbers`.\n",
    "\n",
    "2. **Provide Arguments:** Next, provide the values (arguments) for `number1` and `number2` inside parentheses, separated by a comma. For example, to add 5 and 3, you would write `add_numbers(5, 3)`.\n",
    "\n",
    "3. **Capture the Result:** The function returns a value, which you can assign to a variable or use directly. To save the result of adding 5 and 3 into a variable called `result`, you would write `result <- add_numbers(5, 3)`.\n",
    "\n",
    "4. **Display the Result:** Finally, you can view the result by printing the variable `result` using the `print()` function, like so: `print(result)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe1630-650a-4a2c-91e1-b360aba0cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "result <- add_numbers(5, 3)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7144cb34-42c8-41d2-8255-407cd5e41d49",
   "metadata": {},
   "source": [
    "## Exploring the Hitters Dataset for Regression Analysis\n",
    "\n",
    "In our journey through machine learning techniques, we're utilizing the `Hitters` dataset provided by the `ISLR` package. This dataset offers a wealth of information suitable for regression analysis tasks.\n",
    "\n",
    "The `Hitters` dataset revolves around professional baseball players and encompasses various attributes related to their performance and salaries. Some of the features included in the dataset are:\n",
    "\n",
    "- Player statistics: AtBat (number of times at bat), Hits (number of hits), HmRun (number of home runs), Runs (number of runs scored), RBI (number of runs batted in), Walks (number of walks), etc.\n",
    "- Career statistics: CAtBat (career at bats), CHits (career hits), CHmRun (career home runs), CRuns (career runs scored), CRBI (career runs batted in), CWalks (career walks), etc.\n",
    "- League affiliation: LeagueA (American League), LeagueN (National League).\n",
    "- Division within the league: DivisionW (Western Division).\n",
    "\n",
    "These attributes provide a comprehensive view of a player's performance and background, making the `Hitters` dataset an excellent resource for regression analysis tasks.\n",
    "\n",
    "The `ISLR` package's datasets, including `Hitters`, are renowned for their suitability in statistical learning and machine learning applications. They offer real-world data scenarios, enabling practical application of various machine learning techniques.\n",
    "\n",
    "By leveraging the `Hitters` dataset in our course materials, we aim to provide you with a hands-on learning experience that not only enhances your theoretical understanding but also equips you with practical skills for real-world data analysis in R. Let's dive into loading the `Hitters` dataset and uncovering insights through regression analysis!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41fbef3-0e6c-4f90-8e9e-47fe54e84b30",
   "metadata": {},
   "source": [
    "# Understanding Data Preparation Workflow\n",
    "\n",
    "Let's walk through what we're doing here step by step:\n",
    "\n",
    "- First off, we load up the ISLR library. This is where we get all our cool datasets and functions for learning stats in R.\n",
    "- Then, we dive into the Hitters dataset. Imagine it like a treasure trove of info about baseball players – stats, salaries, the works.\n",
    "- But hey, we gotta clean house first! We sift out any rows with missing info (NA) so our data's squeaky clean.\n",
    "- Next up, we're getting serious with predictions. We create this fancy matrix called X, packed with potential predictors that could help us predict a player's salary. No intercept term here – just straight-up predictors.\n",
    "- Now, we're bringing X into the real world by turning it into a dataframe named 'data'. Think of it like giving shape to our predictions.\n",
    "- But wait, we're not done yet! We need to add in the salary info from the original dataset. So, we tack on the Salary column from Hitters onto our 'data' dataframe. Now, we're cooking with gas!\n",
    "- Just to keep things neat and tidy, we strip away any row names. No clutter here!\n",
    "- Oh, and we've also removed the \"NewLeague\" column from our dataframe to focus on the relevant predictors.\n",
    "- Lastly, to ensure our dataset is free from any missing values, we've removed any remaining rows with NA values.\n",
    "\n",
    "Pretty cool, huh? Now our data is primed and ready for some serious analysis!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65699ac2-f5d5-43e5-8800-9ef139ce952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ISLR library\n",
    "library(ISLR)\n",
    "\n",
    "# Access the Hitters dataset\n",
    "data(Hitters)\n",
    "\n",
    "# Remove rows with NA values to ensure clean data\n",
    "HittersClean <- na.omit(Hitters)\n",
    "\n",
    "# Prepare the predictors matrix without intercept\n",
    "X <- model.matrix(Salary ~ . - 1, data = HittersClean) # Preparing predictors\n",
    "\n",
    "# Convert the matrix to a dataframe\n",
    "data <- as.data.frame(X)\n",
    "\n",
    "# Append the Salary as outcome variable\n",
    "data$salary <- HittersClean$Salary\n",
    "\n",
    "\n",
    "# Remove row names\n",
    "\n",
    "rownames(data) <- NULL\n",
    "\n",
    "# Now 'data' is a dataframe that includes both predictors and the outcome variable\n",
    "\n",
    "data = as.data.frame(data)\n",
    "\n",
    "# Remove the NewLeague column\n",
    "data <- data[, !names(data) %in% \"NewLeague\"]\n",
    "\n",
    "# Remove rows with missing values\n",
    "data <- na.omit(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b5dde-1457-4561-8039-add6beb70f35",
   "metadata": {},
   "source": [
    "## Splitting Data for Machine Learning\r\n",
    "\r\n",
    "Splitting your data into training and testing sets is crucial for assessing the performance of your machine learning models. This step helps you understand how well your model generalizes to new, unseen data. Below is a basic method to split data in R:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee13187f-abde-43bf-98c2-59be88335b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the seed for reproducibility\n",
    "set.seed(123)\n",
    "\n",
    "# Calculate the size of the training set\n",
    "split_ratio = 0.8\n",
    "training_size <- floor(nrow(data) * split_ratio)\n",
    "\n",
    "# Randomly sample row indices for the training set\n",
    "training_indices <- sample(seq_len(nrow(data)), size = training_size)\n",
    "\n",
    "# Create the training set\n",
    "train <- data[training_indices, ]\n",
    "\n",
    "# Create the test set\n",
    "test <- data[-training_indices, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c975d34-38f3-4497-b040-8ba2b108818a",
   "metadata": {},
   "source": [
    "\n",
    "Splitting Data into Train and Test Sets\n",
    "In machine learning, it's crucial to evaluate the performance of your models on unseen data to ensure they can generalize well. One common practice is to split your dataset into separate train and test sets. In this tutorial, we'll walk through how to split your data using R for three different regression methods: Ordinary Least Squares (OLS), Lasso, and Ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59fcd24-9870-45df-b637-8f93b90dd0d9",
   "metadata": {},
   "source": [
    "# Estimating Linear Regression to Predict Salary\n",
    "\n",
    "Let's dive into estimating a linear regression model to predict baseball players' salaries. Here's what we're up to:\n",
    "\n",
    "- We're aiming to understand how various factors influence a player's salary. So, we're fitting a linear regression model using the `lm()` function in R.\n",
    "- This function helps us find the best-fitting line that explains the relationship between a player's salary (our dependent variable) and all the other factors we think might matter (our independent variables).\n",
    "- After we fit our model, it's time to put it to the test! We'll predict salaries for players in our test dataset and see how well our model does.\n",
    "- To measure how accurate our predictions are, we'll calculate something called the Mean Squared Error (MSE). This tells us, on average, how far off our predictions are from the actual salaries.\n",
    "- The lower the MSE, the better our model is at predicting salaries accurately.\n",
    "\n",
    "Let's jump into the code and see how it all plays out:\n",
    "lays out:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55ae73d-c07d-41da-a5ca-35c491647f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = salary ~ ., data = train)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-753.89 -173.98  -11.87  159.32 1815.62 \n",
       "\n",
       "Coefficients: (1 not defined because of singularities)\n",
       "              Estimate Std. Error t value Pr(>|t|)   \n",
       "(Intercept)  214.09783  124.12599   1.725  0.08618 . \n",
       "AtBat         -1.68499    0.75317  -2.237  0.02644 * \n",
       "Hits           5.06495    2.89376   1.750  0.08168 . \n",
       "HmRun         -2.68840    6.86520  -0.392  0.69579   \n",
       "Runs          -0.95353    3.41442  -0.279  0.78034   \n",
       "RBI            1.41046    3.00406   0.470  0.63924   \n",
       "Walks          6.35620    2.11308   3.008  0.00299 **\n",
       "Years        -13.14742   14.12616  -0.931  0.35318   \n",
       "CAtBat        -0.25953    0.15700  -1.653  0.09996 . \n",
       "CHits          0.65158    0.80755   0.807  0.42076   \n",
       "CHmRun         1.29483    1.86077   0.696  0.48737   \n",
       "CRuns          1.25425    0.89170   1.407  0.16119   \n",
       "CRBI           0.46318    0.84092   0.551  0.58242   \n",
       "CWalks        -0.68669    0.39171  -1.753  0.08121 . \n",
       "LeagueA       -6.62438   91.91248  -0.072  0.94262   \n",
       "LeagueN             NA         NA      NA       NA   \n",
       "DivisionW   -120.30537   45.33765  -2.654  0.00864 **\n",
       "PutOuts        0.19444    0.08678   2.240  0.02622 * \n",
       "Assists        0.51924    0.25194   2.061  0.04067 * \n",
       "Errors        -7.33195    4.88072  -1.502  0.13470   \n",
       "NewLeagueN    61.30716   91.82558   0.668  0.50517   \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 311.7 on 190 degrees of freedom\n",
       "Multiple R-squared:  0.6014,\tAdjusted R-squared:  0.5616 \n",
       "F-statistic: 15.09 on 19 and 190 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(ols, newdata = test):\n",
      "“prediction from a rank-deficient fit may be misleading”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 138149.8\n"
     ]
    }
   ],
   "source": [
    "library(glmnet)\n",
    "library(dplyr)\n",
    "\n",
    "# Fit the linear regression model\n",
    "ols <- lm(salary ~ ., data = train)\n",
    "# Display the summary of the model to understand its performance\n",
    "summary(ols)\n",
    "\n",
    "# Predicting the math grades for the test dataset\n",
    "ols$predict_outcome <- predict(ols, newdata = test)\n",
    "\n",
    "# Calculating the Mean Squared Error (MSE) for our predictions\n",
    "predMSEols <- mean((test$salary - ols$predict_outcome)^2)\n",
    "# Print the MSE to the console\n",
    "print(predMSEols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a7ae1-1217-44fb-a31c-16419ddf00f3",
   "metadata": {},
   "source": [
    "# Estimating Lasso and Ridge Regression Models\n",
    "\n",
    "Alrighty, let's expand our horizons and dive into Lasso and Ridge regression models. Here's the plan:\n",
    "\n",
    "- First up, we'll fit a Lasso regression model. Lasso (short for Least Absolute Shrinkage and Selection Operator) is like a regular linear regression model, but with a twist – it adds a penalty term to shrink some coefficients to zero. This helps us deal with multicollinearity and perform variable selection.\n",
    "- We're using the `glmnet()` function in R to estimate our Lasso model. We're throwing in the first 25 columns of our dataset as predictors and the salary as our outcome variable.\n",
    "- But wait, how do we know if our Lasso model is any good? That's where cross-validation comes in! We'll use `cv.glmnet()` to perform cross-validation and find the optimal lambda value. Lambda is the tuning parameter that controls the amount of shrinkage in our model. We want to find the lambda that gives us the lowest Mean Squared Error (MSE) on our validation data.\n",
    "- We'll perform 5-fold cross-validation, meaning we split our data into 5 parts, train our model on 4 parts, and test it on the remaining part. We do this 5 times, rotating which part is the validation set each time.\n",
    "- Once we have our optimal lambda value, we'll have a solid Lasso model ready to make some killer predictions!\n",
    "\n",
    "Let's rock and roll with the code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b98642-d9aa-4e37-a1a0-f6e543e892e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate a Lasso model using all predictors except the outcome variable\n",
    "lasso <- glmnet(as.matrix(train[, -ncol(train)]), train$salary, alpha = 1)\n",
    "\n",
    "# Perform cross-validation to find the optimal lambda value\n",
    "lasso.cv <- cv.glmnet(as.matrix(train[, -ncol(train)]), train$salary, type.measure = \"mse\", nfolds = 5, alpha = 1)\n",
    "\n",
    "\n",
    "\n",
    "ridge <- glmnet(as.matrix(train[, -ncol(train)]), train$salary, alpha = 0)\n",
    "# Cross-validate the Ridge model \n",
    "ridge.cv <- cv.glmnet(as.matrix(train[, -ncol(train)]), train$salary, type.measure = \"mse\", nfolds = 5, alpha = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0151d2-3c40-48b4-8706-4c1ade653460",
   "metadata": {},
   "source": [
    "## Results and Next Steps\n",
    "\n",
    "After running the cross-validation, the optimal lambda λ value is stored within `lasso.cv` and can be accessed using `lasso.cv$lambda.min` for the lambda that minimizes MSE, or `lasso.cv$lambda.1se` for the most regularized model within one standard error of the minimum.\n",
    "\n",
    "Understanding and selecting the optimal lambda allows us to balance model complexity and accuracy, tailoring our Lasso regression model to perform optimally on unseen data.\n",
    "\n",
    "In the next steps of our analysis, we would use this optimal lambda value to re-estimate our Lasso model or proceed with model evaluation, such as calculating MSE on a test set to gauge the model's prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf84f9f-ced1-4a19-a5c7-35cf45259e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Optimal lambda that minimizes cross-validated MSE: 3.09038156237519\"\n",
      "[1] \"Optimal lambda using one-standard-error-rule: 80.1961497682695\"\n",
      "[1] \"Optimal lambda that minimizes cross-validated MSE: 29.4991895086142\"\n",
      "[1] \"Optimal lambda using one-standard-error-rule: 2565.68906531502\"\n"
     ]
    }
   ],
   "source": [
    "# Print the optimal lambda value\n",
    "print(paste0(\"Optimal lambda that minimizes cross-validated MSE: \", lasso.cv$lambda.min))\n",
    "print(paste0(\"Optimal lambda using one-standard-error-rule: \", lasso.cv$lambda.1se))\n",
    "\n",
    "print(paste0(\"Optimal lambda that minimizes cross-validated MSE: \", ridge.cv$lambda.min))\n",
    "print(paste0(\"Optimal lambda using one-standard-error-rule: \", ridge.cv$lambda.1se))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff5547-7e2f-4076-b0d2-736a153ea714",
   "metadata": {},
   "source": [
    "###  Evaluating Model Performance with Test Sample Mean Squared Error (MSE)\n",
    "\n",
    "Following the coefficient analysis, we proceed to calculate the Mean Squared Error (MSE) in the test sample. The test sample MSE enables us to assess the performance of our Lasso model on unseen data and compare it with other estimators. By evaluating the model's accuracy on a separate test dataset, we ensure that our Lasso regression model can generalize effectively beyond the training data, providing reliable predictions in practical scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dc272ec-59a0-47ad-97bc-1ec942fd28da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE: 130313.877940595\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Predict using the fitted Lasso model\n",
    "lasso$predict_outcome <- predict(lasso, newx = as.matrix(test[, -ncol(test)]), s = lasso.cv$lambda.min)\n",
    "\n",
    "# Calculate the MSE\n",
    "predMSElasso <- mean((test$salary - lasso$predict_outcome)^2)\n",
    "print(paste0(\"MSE: \", predMSElasso))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e059af06-f36a-4c5b-991b-d838bae7a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE: 132630.476586086\"\n"
     ]
    }
   ],
   "source": [
    "# Predict using the fitted Lasso model\n",
    "ridge$predict_outcome <- predict(ridge, newx = as.matrix(test[, -ncol(test)]), s = ridge.cv$lambda.min)\n",
    "\n",
    "# Calculate the MSE\n",
    "predMSEridge <- mean((test$salary - ridge$predict_outcome )^2)\n",
    "print(paste0(\"MSE: \", predMSEridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ae099-fe5e-42ef-a81b-3919bfe2150b",
   "metadata": {},
   "source": [
    "# Comparing Regression Models: OLS, Lasso, and Ridge\r\n",
    "\r\n",
    "The output you've observed represents the mean squared error (MSE) values for three different regression models applied to your dataset: Ordinary Least Squares (OLS), Lasso, and Ridge regression. MSE is a common measure used to quantify the error of a model's predictions, where a lower MSE value indicates a model with better predictive accuracy. Below is an explanation of each model's MSE in your output:\r\n",
    "\r\n",
    "- **OLS Regression MSE (138149.8):** This MSE value is associated with the OLS regression model, the simplest form of linear regression that does not apply any regularization. The relatively high MSE suggests that the OLS model might be overfitting or not effectively capturing the underlying data structure.\r\n",
    "\r\n",
    "- **Lasso Regression MSE (130313.9):** Lasso regression, which incorporates an L1 penalty leading to coefficient sparsity (setting some coefficients to zero), shows a slightly improved MSE compared to OLS. This indicates better generalization, likely due to its feature selection effect, which helps in reducing overfitting.\r\n",
    "\r\n",
    "- **Ridge Regression MSE (132630.5):** The MSE for Ridge regression is between the MSEs of OLS and Lasso. Ridge regression uses an L2 penalty to shrink the coefficients but not to zero. This suggests that Ridge regression is effective in predicting the data for this particular scenario.\r\n",
    "\r\n",
    "In essence, this comparison indicates that for the specific dataset and conditions at hand, Lasso regression outperforms both OLS and Ridge regression in terms of predictive accuracy. This underscores the benefit of incorporating regularization techniques, such as L1 penalty, to enhance model performance by mitigating overfitting and dealing more adeptly with multicollinearity.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c903add7-b111-4be9-9b67-20caf60312bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 138149.8 130313.9 132630.5\n"
     ]
    }
   ],
   "source": [
    "print(c(predMSEols, predMSElasso, predMSEridge))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
