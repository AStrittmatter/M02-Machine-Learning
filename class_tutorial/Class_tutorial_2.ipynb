{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569fe9b5-2404-451a-8eb6-1933abc38e1f",
   "metadata": {},
   "source": [
    "# Automating Dataset Handling in R\n",
    "\n",
    "In this tutorial, we explore a practical and efficient approach to getting started with a data science project in R: automating the download, unzipping, and loading of datasets. This process not only saves time but also introduces you to the concept of functions in R—a fundamental skill for any aspiring data scientist.\n",
    "\n",
    "### Why Create a Custom Function?\n",
    "\n",
    "- **Time-saving:** Automating repetitive tasks like downloading, unzipping, and loading datasets saves a significant amount of time.\n",
    "- **Skill Enhancement:** Building a custom function for these tasks is not only practical for any data science project but also an excellent way to understand the power and flexibility of functions in R.\n",
    "\n",
    "### Tutorial Overview\n",
    "\n",
    "This tutorial walks you through creating a custom function to automate the process of handling the Student Performance dataset from the UCI Machine Learning Repository. Here's what we'll cover:\n",
    "\n",
    "1. **Creating a Function in R:** We'll start by defining a custom function tailored to automate the download, unzip, and load process.\n",
    "2. **Automating Dataset Handling:** We'll use the Student Performance dataset as a case study to demonstrate how the function works in practice.\n",
    "3. **Enhancing R Data Science Skills:** Through this process, you'll gain a deeper understanding of how functions in R can be used to streamline your data science skills with R.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd19ccf-6812-42b5-91c9-9b04b86b28e5",
   "metadata": {},
   "source": [
    "## Creating a Function in R\n",
    "\n",
    "To create a function in R, you use the `function()` keyword. The basic syntax of a function is as follows:\n",
    "\n",
    "```R\n",
    "my_function <- function(arg1, arg2, ...) {\n",
    "  # Function body\n",
    "  # Code to execute\n",
    "  # Return a\n",
    "```\n",
    "\n",
    "\n",
    "Let's create a very simple function that adds two numbers together. This function will take two arguments (the numbers to be added) and will return their sum. value\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50003885-0cf8-444e-ab30-8444fb7d46a0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add_numbers <- function(number1, number2) {\n",
    "  sum <- number1 + number2\n",
    "  return(sum)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee6839-c97a-419a-9ff3-38c073609352",
   "metadata": {},
   "source": [
    "To use the `add_numbers` function, follow these steps:\n",
    "\n",
    "1. **Call the Function:** Start by writing the name of the function you want to use, in this case, `add_numbers`.\n",
    "\n",
    "2. **Provide Arguments:** Next, provide the values (arguments) for `number1` and `number2` inside parentheses, separated by a comma. For example, to add 5 and 3, you would write `add_numbers(5, 3)`.\n",
    "\n",
    "3. **Capture the Result:** The function returns a value, which you can assign to a variable or use directly. To save the result of adding 5 and 3 into a variable called `result`, you would write `result <- add_numbers(5, 3)`.\n",
    "\n",
    "4. **Display the Result:** Finally, you can view the result by printing the variable `result` using the `print()` function, like so: `print(result)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe1630-650a-4a2c-91e1-b360aba0cd05",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "result <- add_numbers(11, 3)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6373101-779e-4025-8ac3-c3a7b55ec485",
   "metadata": {},
   "source": [
    "## Exploring the Hitters Dataset for Regression Analysis\n",
    "\n",
    "In our journey through machine learning techniques, we're utilizing the `Hitters` dataset provided by the `ISLR` package. This dataset offers a wealth of information suitable for regression analysis tasks.\n",
    "\n",
    "The `Hitters` dataset revolves around professional baseball players and encompasses various attributes related to their performance and salaries. Some of the features included in the dataset are:\n",
    "\n",
    "- Player statistics: `AtBat` (number of times at bat), `Hits` (number of hits), `HmRun` (number of home runs), `Runs` (number of runs scored), `RBI` (number of runs batted in), `Walks` (number of walks), etc.\n",
    "- League affiliation: `LeagueA` (American League), `LeagueN` (National League).\n",
    "- Division within the league: `DivisionW` (Western Division).\n",
    "\n",
    "These attributes provide a comprehensive view of a player's performance and background, making the `Hitters` dataset an excellent resource for regression analysis tasks.\n",
    "\n",
    "The `ISLR` package's datasets, including `Hitters`, are renowned for their suitability in statistical learning and machine learning applications. They offer real-world data scenarios, enabling practical application of various machine learning techniques.\n",
    "\n",
    "By leveraging the `Hitters` dataset in our course materials, we aim to provide you with a hands-on learning experience that not only enhances your theoretical understanding but also equips you with practical skills for real-world data analysis in R. Let's dive into loading the `Hitters` dataset and uncovering insights through regression analysis!\n",
    "\n",
    "<span style=\"color:red; font-weight:bold; font-size:small;\">\n",
    "- Note for Class: On purpose, we are not relying on career statistics variables. (You will see later why)\n",
    "</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41fbef3-0e6c-4f90-8e9e-47fe54e84b30",
   "metadata": {},
   "source": [
    "# Understanding Data Preparation Workflow\n",
    "\n",
    "Let's walk through what we're doing here step by step:\n",
    "\n",
    "- First off, we load up the ISLR library. This is where we get all our cool datasets and functions for learning stats in R.\n",
    "- Then, we dive into the Hitters dataset. Imagine it like a treasure trove of info about baseball players – stats, salaries, the works.\n",
    "- But hey, we gotta clean first! We sift out any rows with missing info (NA) so our data's squeaky clean.\n",
    "- Next up, we're getting serious with predictions. We create this fancy matrix called X, packed with potential predictors that could help us predict a player's salary. No intercept term here – just straight-up predictors.\n",
    "- Now, we're bringing X into the real world by turning it into a dataframe named 'data'. Think of it like giving shape to our predictions.\n",
    "- But wait, we're not done yet! We need to add in the salary info from the original dataset. So, we tack on the Salary column from Hitters onto our 'data' dataframe. Now, we're cooking with gas!\n",
    "- Just to keep things neat and tidy, we strip away any row names. No clutter here!\n",
    "- Oh, and we've also removed the \"NewLeague\" column from our dataframe to focus on the relevant predictors.\n",
    "- Lastly, to ensure our dataset is free from any missing values, we've removed any remaining rows with NA values.\n",
    "\n",
    "Pretty cool, huh? Now our data is primed and ready for some serious analysis!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65699ac2-f5d5-43e5-8800-9ef139ce952f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load the ISLR library\n",
    "library(ISLR)\n",
    "\n",
    "# Access the Hitters dataset\n",
    "data(Hitters)\n",
    "\n",
    "# Remove rows with NA values to ensure clean data\n",
    "HittersClean <- na.omit(Hitters)\n",
    "\n",
    "# Prepare the predictors matrix without intercept\n",
    "X <- model.matrix(Salary ~ . - 1, data = HittersClean) # Preparing predictors\n",
    "\n",
    "# Convert the matrix to a dataframe\n",
    "data <- as.data.frame(X)\n",
    "\n",
    "# Append the Salary as outcome variable\n",
    "data$salary <- HittersClean$Salary\n",
    "\n",
    "\n",
    "# Remove row names\n",
    "\n",
    "rownames(data) <- NULL\n",
    "\n",
    "# Now 'data' is a dataframe that includes both predictors and the outcome variable\n",
    "\n",
    "data = as.data.frame(data)\n",
    "\n",
    "# LeagueN\n",
    "# Remove the NewLeague column\n",
    "data <- data[, !names(data) %in% \"NewLeague\"]\n",
    "\n",
    "# Remove rows with missing values\n",
    "data <- na.omit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b5dde-1457-4561-8039-add6beb70f35",
   "metadata": {},
   "source": [
    "## Splitting Data for Machine Learning\n",
    "\n",
    "Splitting your data into training and testing sets is crucial for assessing the performance of your machine learning models. This step helps you understand how well your model generalizes to new, unseen data. Below is a basic method to split data in R:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13187f-abde-43bf-98c2-59be88335b96",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set the seed for reproducibility\n",
    "set.seed(123)\n",
    "\n",
    "# Calculate the size of the training set\n",
    "split_ratio = 0.8\n",
    "training_size <- floor(nrow(data) * split_ratio)\n",
    "\n",
    "# Randomly sample row indices for the training set\n",
    "training_indices <- sample(seq_len(nrow(data)), size = training_size)\n",
    "\n",
    "# Create the training set\n",
    "train <- data[training_indices, ]\n",
    "\n",
    "# Create the test set\n",
    "test <- data[-training_indices, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c975d34-38f3-4497-b040-8ba2b108818a",
   "metadata": {},
   "source": [
    "\n",
    "Splitting Data into Train and Test Sets\n",
    "In machine learning, it's crucial to evaluate the performance of your models on unseen data to ensure they can generalize well. One common practice is to split your dataset into separate train and test sets. In this tutorial, we'll walk through how to split your data using R for three different regression methods: Ordinary Least Squares (OLS), Lasso, and Ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487d813-9667-4767-ae4e-698807679446",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-weight:bold; font-size:xx-large;\">\n",
    "# Time for a breakout session \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59fcd24-9870-45df-b637-8f93b90dd0d9",
   "metadata": {},
   "source": [
    "# Estimating Linear Regression to Predict Salary\n",
    "\n",
    "Let's dive into estimating a linear regression model to predict baseball players' salaries. Here's what we're up to:\n",
    "\n",
    "- We're aiming to understand how various factors influence a player's salary. So, we're fitting a linear regression model using the `lm()` function in R.\n",
    "- This function helps us find the best-fitting line that explains the relationship between a player's salary (our dependent variable) and all the other factors we think might matter (our independent variables).\n",
    "- After we fit our model, it's time to put it to the test! We'll predict salaries for players in our test dataset and see how well our model does.\n",
    "- To measure how accurate our predictions are, we'll calculate something called the Mean Squared Error (MSE). This tells us, on average, how far off our predictions are from the actual salaries.\n",
    "- The lower the MSE, the better our model is at predicting salaries accurately.\n",
    "\n",
    "Let's jump into the code and see how it all plays out:\n",
    "lays out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ae73d-c07d-41da-a5ca-35c491647f5f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "library(dplyr)\n",
    "\n",
    "# Fit the linear regression model\n",
    "ols <- lm(salary ~ ., data = train)\n",
    "# Display the summary of the model to understand its performance\n",
    "summary(ols)\n",
    "\n",
    "# Predicting the salary for the test dataset\n",
    "ols$predict_outcome <- predict(ols, newdata = test)\n",
    "\n",
    "# Calculating the Mean Squared Error (MSE) for our predictions\n",
    "predMSEols <- mean((test$salary - ols$predict_outcome)^2)\n",
    "# Print the MSE to the console\n",
    "print(predMSEols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a7ae1-1217-44fb-a31c-16419ddf00f3",
   "metadata": {},
   "source": [
    "# Estimating Lasso and Ridge Regression Models\n",
    "\n",
    "Alrighty, let's expand our horizons and dive into Lasso and Ridge regression models. Here's the plan:\n",
    "\n",
    "- First up, we'll fit a Lasso regression model. Lasso (short for Least Absolute Shrinkage and Selection Operator) is like a regular linear regression model, but with a twist – it adds a penalty term to shrink some coefficients to zero. This helps us deal with multicollinearity and perform variable selection.\n",
    "- We're using the `glmnet()` function in R to estimate our Lasso model. We're using salary as our outcome variable.\n",
    "- But wait, how do we know if our Lasso model is any good? That's where cross-validation comes in! We'll use `cv.glmnet()` to perform cross-validation and find the optimal lambda value. Lambda is the tuning parameter that controls the amount of shrinkage in our model. We want to find the lambda that gives us the lowest Mean Squared Error (MSE) on our validation data.\n",
    "- We'll perform 5-fold cross-validation, meaning we split our data into 5 parts, train our model on 4 parts, and test it on the remaining part. We do this 5 times, rotating which part is the validation set each time.\n",
    "- Once we have our optimal lambda value, we'll have a solid Lasso model ready to make some killer predictions!\n",
    "\n",
    "Let's rock and roll with the code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f0063-dfa8-46e3-b62d-2e4e0a786289",
   "metadata": {},
   "source": [
    "## Advancing to Lasso Regression: Streamlining Predictive Analysis\n",
    "\n",
    "In this stage, we upgrade our regression technique to Lasso regression, introducing a penalty (`alpha = 1`) to enhance model precision. We start by leveraging the Lasso constraint to minimize residual error and shrink regression coefficients. Our goal remains clear: predict `train$salary` values based on specified predictors. After this, we'll delve into visualizing our regression insights for clearer interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b98642-d9aa-4e37-a1a0-f6e543e892e6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Estimate a Lasso model using all predictors except the outcome variable\n",
    "lasso <- glmnet(as.matrix(train[, -ncol(train)]), train$salary, alpha = 1)\n",
    "\n",
    "plot(lasso, xvar = \"lambda\", label = TRUE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8b3ac-7bc9-4904-80a4-be3289f108fd",
   "metadata": {},
   "source": [
    "The plot showcases Lasso regression's journey with predictors from the Hitters dataset. As the log lambda value increases, coefficients shrink towards zero—a hallmark of Lasso for feature selection and regularization. Initially, with lower lambda, most coefficients remain non-zero, but as lambda rises, more coefficients become zero, simplifying the model. The top numbers indicate the quantity of active predictors at different lambda thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7542a14-1d80-4499-8a2c-c1c5ba8dc028",
   "metadata": {},
   "source": [
    "## Optimizing Regularized Regression: Tuning $\\lambda$ through Cross-Validation\n",
    "\n",
    "In the realms of Lasso and Ridge regression, the penalty term $\\lambda$ is pivotal for balancing model complexity and prediction accuracy. Mastering the selection of $\\lambda$ necessitates a firm grasp of cross-validation techniques and the variance-bias trade-off, core concepts in statistical learning.\n",
    "\n",
    "### The Cross-Validation Process\n",
    "\n",
    "Cross-validation (CV) stands as a robust method for gauging the predictive performance of statistical models and fine-tuning parameters like $\\lambda$. Here's how CV facilitates this process:\n",
    "\n",
    "1. **Partitioning**: The dataset splits into $k$ equally sized folds, ensuring each data point tests against a model trained on unseen data—a crucial step for assessing model generalizability.\n",
    "\n",
    "2. **Grid of $\\lambda$ Values**: A comprehensive range of $\\lambda$ values explores, seeking the optimal balance between model complexity and predictive accuracy.\n",
    "\n",
    "3. **Model Training and Validation**: Each $\\lambda$ undergoes iterative training on $k-1$ folds and testing on the remaining fold. Metrics like Mean Squared Error (MSE) evaluate model performance.\n",
    "\n",
    "4. **Average Prediction Errors**: Across all folds for each $\\lambda$, average errors accumulate, revealing the model's performance under varying levels of regularization.\n",
    "\n",
    "5. **Selecting $\\lambda$**: The optimal $\\lambda$ minimizes cross-validated prediction error. Alternatively, the one-standard-error rule selects the simplest model with an error within one standard deviation of the lowest error.\n",
    "\n",
    "### Grasping the Variance-Bias Trade-off\n",
    "\n",
    "Understanding the variance-bias trade-off is pivotal when tuning $\\lambda$:\n",
    "\n",
    "- **High Bias**: Oversimplified models (high bias) struggle to capture complex patterns, leading to underfitting and poor performance.\n",
    "\n",
    "- **High Variance**: Overly complex models (high variance) capture random noise, resulting in overfitting and poor generalization.\n",
    "\n",
    "- **Balancing with $\\lambda$**: The regularization parameter $\\lambda$ modulates this trade-off. As $\\lambda$ increases, model complexity decreases, reducing variance but potentially increasing bias.\n",
    "\n",
    "#### Linking to Cross-Validation\n",
    "\n",
    "Cross-validation plays a pivotal role in navigating this trade-off:\n",
    "\n",
    "- **Model Evaluation**: Estimates model error on unseen data, ensuring robust performance beyond the training set.\n",
    "\n",
    "- **Optimal $\\lambda$ Selection**: Identifies $\\lambda$ minimizing validation set error, guarding against overfitting and ensuring generalization.\n",
    "\n",
    "- **Visualizing Trade-off**: Provides a validation curve illustrating MSE for various $\\lambda$ values, pinpointing the optimal balance.\n",
    "\n",
    "Before diving in, establishing a seed for replicability ensures consistent and reproducible results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43209dc8-51fb-4e82-9e1c-24a9f58d408e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Perform cross-validation to find the optimal lambda value\n",
    "lasso.cv <- cv.glmnet(as.matrix(train[, -ncol(train)]), train$salary, type.measure = \"mse\", nfolds = 5, alpha = 1)\n",
    "\n",
    "# Plot the cross-validation results\n",
    "plot(lasso.cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bef881-f138-417b-9acc-fb446362d1a1",
   "metadata": {},
   "source": [
    "## Deciphering the Bias-Variance Trade-off through Visualization\n",
    "\n",
    "The cross-validation plot serves as a visual compass, guiding our understanding of the bias-variance trade-off within Lasso regression:\n",
    "\n",
    "- **High Bias**: Rightmost \\( $\\lambda$ \\) values signify a model with elevated bias, indicating simplicity that may overlook data intricacies, potentially leading to increased training errors.\n",
    "\n",
    "- **High Variance**: Conversely, lower \\( $\\lambda$ \\) values on the left suggest a model with reduced bias but heightened variance, closely fitting the training data and risking overfitting.\n",
    "\n",
    "- **Optimal \\( $\\lambda$ \\) Spotting**: Nestled at the plot's nadir lies the optimal \\( $\\lambda$ \\), striking a harmonious balance between bias and variance, minimizing mean squared error (MSE) across cross-validation folds.\n",
    "\n",
    "- **MSE Minimization**: Pinpointing \\( $\\lambda$ \\) associated with the lowest MSE hones in on superior model performance for unseen data.\n",
    "\n",
    "- **One-Standard-Error Rule**: For a cautious approach, adopting the one-standard-error rule selects the largest \\( $\\lambda$ \\) within one standard error above the minimum MSE, fostering a model less prone to overfitting.\n",
    "\n",
    "This visual journey empowers us to make informed decisions, ensuring our Lasso regression model strikes the perfect equilibrium between simplicity and predictive power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857874b0-0376-403b-81a6-87552125e8dd",
   "metadata": {},
   "source": [
    "## Analyzing Lasso Coefficients and Calculating train Sample MSE\n",
    "\n",
    "In the code snippet below, we examine the coefficients of the Lasso model corresponding to the optimal lambda value determined through cross-validation. In Lasso regression, certain coefficients may take on a value of zero, indicating that the associated control variables are excluded from the model. This property of Lasso aids in simplifying the model by removing less relevant variables, thereby enhancing interpretability and generalization to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e6b663-21bc-4ecc-9bb1-ccc0ca5ee2ec",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Print Lasso coefficients\n",
    "print(coef(lasso.cv, s = \"lambda.min\"))\n",
    "\n",
    "# Save for later comparison\n",
    "coef_lasso <- coef(lasso.cv, s = \"lambda.min\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593e105-bf74-4886-ba7d-76653606277a",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-weight:bold; font-size:xx-large;\">\n",
    "# Time for a breakout session \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa7270-53d7-41b8-aaff-d0b871b7de2f",
   "metadata": {},
   "source": [
    "# Transitioning to Ridge Regression: Enhancing Predictive Analysis\n",
    "\n",
    "In this stage, we transition our regression methodology to Ridge regression, implementing a penalty (`alpha = 0`) to refine model accuracy.  Following this, we'll embark on visualizing our regression findings for enhanced comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d85dc-d2f5-4b8d-8d7a-e88aa1bcc6a7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ridge <- glmnet(as.matrix(train[, -ncol(train)]), train$salary, alpha = 0)\n",
    "# Cross-validate the Ridge model \n",
    "plot(ridge, xvar = \"lambda\", label = TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d56577-411a-487f-b0fd-6bd962e81c4b",
   "metadata": {},
   "source": [
    "## Visualizing Ridge Regression Coefficients: Understanding Regularization\n",
    "\n",
    "Can you spot what's different here? In this visualization, it's evident that the model retains all variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0237e4-3a69-44f6-b4da-451dfea7f90e",
   "metadata": {},
   "source": [
    "##  Again by cross-validation trade-off, we visualise the Bias variance\n",
    "\n",
    "The plot is a visualization of model performance metrics as a function of model complexity (lambda penalty in this case for ridge regression), which can be linked to the bias-variance trade-off.\n",
    "Lower values of lambda correspond to higher complexity (low bias, high variance), and as lambda increases, the model complexity decreases (higher bias, lower variance).\n",
    "The point where the red line (representing MSE) is at its minimum suggests the optimal balance between bias and variance, minimizing the total expected error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e5146-7519-42c0-ba92-146799663f1d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ridge.cv <- cv.glmnet(as.matrix(train[, -ncol(train)]), train$salary, type.measure = \"mse\", nfolds = 5, alpha = 0, lambda.min.ratio = 0 )\n",
    "plot(ridge.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e7047-7190-4926-ab29-5c4d828c094a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Print Ridge coefficients\n",
    "print(coef(ridge.cv, s = \"lambda.min\"))\n",
    "\n",
    "# Save for later comparison\n",
    "coef_ridge <- coef(ridge.cv, s = \"lambda.min\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b5fe3f-5afc-48ea-9258-90fc73876fd4",
   "metadata": {},
   "source": [
    "In contrast to the Lasso model, the Ridge model keeps all control variables. Accordingly, Ridge is suited for dense models. In coparison to OLS, the Ridge coefficients are shrunken towards zero.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0151d2-3c40-48b4-8706-4c1ade653460",
   "metadata": {},
   "source": [
    "## Results and Next Steps\n",
    "\n",
    "After running the cross-validation, the optimal lambda λ value is stored within `lasso.cv` and can be accessed using `lasso.cv$lambda.min` for the lambda that minimizes MSE, or `lasso.cv$lambda.1se` for the most regularized model within one standard error of the minimum.\n",
    "\n",
    "Understanding and selecting the optimal lambda allows us to balance model complexity and accuracy, tailoring our Lasso regression model to perform optimally on unseen data.\n",
    "\n",
    "In the next steps of our analysis, we would use this optimal lambda value to re-estimate our Lasso model or proceed with model evaluation, such as calculating MSE on a test set to gauge the model's prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf84f9f-ced1-4a19-a5c7-35cf45259e90",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Print the optimal lambda value\n",
    "print(paste0(\"Optimal lambda that minimizes cross-validated MSE: \", lasso.cv$lambda.min))\n",
    "print(paste0(\"Optimal lambda using one-standard-error-rule: \", lasso.cv$lambda.1se))\n",
    "\n",
    "\n",
    "print(paste0(\"Optimal lambda that minimizes cross-validated MSE: \", ridge.cv$lambda.min))\n",
    "print(paste0(\"Optimal lambda using one-standard-error-rule: \", ridge.cv$lambda.1se))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff5547-7e2f-4076-b0d2-736a153ea714",
   "metadata": {},
   "source": [
    "###  Evaluating Model Performance with Test Sample Mean Squared Error (MSE)\n",
    "\n",
    "Following the coefficient analysis, we proceed to calculate the Mean Squared Error (MSE) in the test sample. The test sample MSE enables us to assess the performance of our Lasso model on unseen data and compare it with other estimators. By evaluating the model's accuracy on a separate test dataset, we ensure that our Lasso regression model can generalize effectively beyond the training data, providing reliable predictions in practical scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc272ec-59a0-47ad-97bc-1ec942fd28da",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predict using the fitted Lasso model\n",
    "lasso$predict_outcome <- predict(lasso, newx = as.matrix(test[, -ncol(test)]), s = lasso.cv$lambda.min)\n",
    "\n",
    "# Calculate the MSE\n",
    "predMSElasso <- mean((test$salary - lasso$predict_outcome)^2)\n",
    "print(paste0(\"MSE: \", predMSElasso))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e059af06-f36a-4c5b-991b-d838bae7a26d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Predict using the fitted Lasso model\n",
    "ridge$predict_outcome <- predict(ridge, newx = as.matrix(test[, -ncol(test)]), s = ridge.cv$lambda.min)\n",
    "\n",
    "# Calculate the MSE\n",
    "predMSEridge <- mean((test$salary - ridge$predict_outcome )^2)\n",
    "print(paste0(\"MSE: \", predMSEridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ae099-fe5e-42ef-a81b-3919bfe2150b",
   "metadata": {},
   "source": [
    "# Comparing Regression Models: OLS, Lasso, and Ridge\n",
    "\n",
    "The output you've observed represents the mean squared error (MSE) values for three different regression models applied to your dataset: Ordinary Least Squares (OLS), Lasso, and Ridge regression. MSE is a common measure used to quantify the error of a model's predictions, where a lower MSE value indicates a model with better predictive accuracy. Below is an explanation of each model's MSE in your output:\n",
    "\n",
    "- **OLS Regression MSE (138149.8):** This MSE value is associated with the OLS regression model, the simplest form of linear regression that does not apply any regularization. The relatively high MSE suggests that the OLS model might be overfitting or not effectively capturing the underlying data structure.\n",
    "\n",
    "- **Lasso Regression MSE (130313.9):** Lasso regression, which incorporates an L1 penalty leading to coefficient sparsity (setting some coefficients to zero), shows a slightly improved MSE compared to OLS. This indicates better generalization, likely due to its feature selection effect, which helps in reducing overfitting.\n",
    "\n",
    "- **Ridge Regression MSE (132630.5):** The MSE for Ridge regression is between the MSEs of OLS and Lasso. Ridge regression uses an L2 penalty to shrink the coefficients but not to zero. This suggests that Ridge regression is effective in predicting the data for this particular scenario.\n",
    "\n",
    "In essence, this comparison indicates that for the specific dataset and conditions at hand, Lasso regression outperforms both OLS and Ridge regression in terms of predictive accuracy. This underscores the benefit of incorporating regularization techniques, such as L1 penalty, to enhance model performance by mitigating overfitting and dealing more adeptly with multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903add7-b111-4be9-9b67-20caf60312bd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(c(predMSEols, predMSElasso, predMSEridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4353ee7-648b-4918-b3b6-bcc9fc7911d1",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-weight:bold; font-size:xx-large;\">\n",
    "# Time for a breakout session \n",
    "</span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
